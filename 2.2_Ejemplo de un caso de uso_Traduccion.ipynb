{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso de uso: traducción de un texto en bloque\n",
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "<i class=\"fa fa-bug\"></i>\n",
    "Si no queréis perder los resultados de ejemplo, **no ejecutéis** el cuaderno de jupyter sin tener una clave propia de la API de OpenAI. Estos cuadernos solo cumplen una función ilustrativa de los códigos y formas de utilizar el modelo GPT-3 con Python. En caso de disponer de una **clave**, guardadla en un archivo **.env** para mayor seguridad como **un texto entrecomillado asignado a la variable OPENAI_API_KEY**.\n",
    "</div>\n",
    "\n",
    "## Autentificación\n",
    "\n",
    "La API de OpenAI utiliza claves de API para la autentificación. \n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    \n",
    "<i class=\"fa fa-exclamation-circle\"></i>\n",
    "Recuerda que tu clave de API es un secreto. No la compartas con otros ni la expongas en ningún código del lado del cliente (navegadores, aplicaciones). Las solicitudes de producción deben dirigirse a través de su propio servidor *backend*, donde su clave de API puede cargarse de forma segura desde una variable de entorno o un servicio de gestión de claves.\n",
    "\n",
    "</div>\n",
    "\n",
    "Todas las solicitudes de API deben incluir su clave de API, es importante almacenar en un documento seguro la llave. Para ello, crea un archivo nuevo `.env` para almacenarla en su interior de la siguiente forma:\n",
    "\n",
    "`OPENAI_API_KEY = \"MI_API_KEY\"`\n",
    "\n",
    "Con esto, para recuperar la clave de la API, tendremos que usar el **getenv** de `os`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Como expuse al final del cuaderno 3.1, el problema de gestionar cada párrafo por separado, supone un problema para la coherencia y continuidad del texto para la traducción; lo ideal sería pasarle todo el conjunto de texto de una vez, que lo gestione y traduzca el bloque.\n",
    "\n",
    "El problema que se presenta en este caso es que, al hacerlo, perdemos las referencias de los párrafos. Normalmente, cuando traducimos oraciones y frases, estas pueden variar en número de palabras, pero el número de frases y oraciones de entrada y salida es raro que varíen; por esta razón, podríamos generar un diccionario que contenga, por cada llave (número de párrafo) el número de puntos (frases) que contiene.\n",
    "\n",
    "Ese diccionario de referencia nos puede servir para recuperar los párrafos en la traducción antes de guardar el documento.\n",
    "\n",
    "**¿Por qué elegir esta opción y no añadir *\\n* como unión de la lista de párrafos?** Aunque es una opción razonable y sencilla, debemos tener en cuenta que estamos trabajando con un modelo que presenta mucha flexibilidad a la hora de dar una respuesta, lo que podría significar que se *pierda* o decida eliminar alguno de los saltos de línea en el proceso. Por esta misma razón, al trabajar con un modelo en bruto, es siempre recomendable que los elementos que genere de peticiones que requieran cierto grado de equivalencia (como una traducción) sean revisados con cuidado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar biblioteca si no la tenéis\n",
    "#!pip3 install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua, rocín flaco y galgo corredor. Una olla de algo más vaca que carnero, salpicón las más noches, duelos y quebrantos los sábados, lantejas los viernes, algún palomino de añadidura los domingos, consumían las tres partes de su hacienda. El resto della concluían sayo de velarte, calzas de velludo para las fiestas, con sus pantuflos de lo mesmo, y los días de entresemana se honraba con su vellorí de lo más fino. Tenía en su casa una ama que pasaba de los cuarenta y una sobrina que no llegaba a los veinte, y un mozo de campo y plaza que así ensillaba el rocín como tomaba la podadera. Frisaba la edad de nuestro hidalgo con los cincuenta años. Era de complexión recia, seco de carnes, enjuto de rostro, gran madrugador y amigo de la caza. Quieren decir que tenía el sobrenombre de «Quijada», o «Quesada», que en esto hay alguna diferencia en los autores que deste caso escriben, aunque por conjeturas verisímiles se deja entender que se llamaba «Quijana». Pero esto importa poco a nuestro cuento: basta que en la narración dél no se salga un punto de la verdad.\n",
      "{0: 3, 1: 4, 2: 1}\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "\n",
    "# ----------------------------------------------- CARGA DEL DOCUMENTO CON docx.Document\n",
    "documento = Document(docx='./documentos/para_traducir.docx').paragraphs\n",
    "\n",
    "# ----------------------------------------------- UNIMOS TODOS LOS PÁRRAFOS EN UNA ÚNICA LISTA\n",
    "doc = []\n",
    "for parrafos in documento:\n",
    "    doc.append(parrafos.text)\n",
    "# ----------------------------------------------- CREAMOS EL DICCIONARIO DE REFERENCIA PARA LOS PÁRRAFOS\n",
    "doc_split = {}\n",
    "for val in range(len(doc)):\n",
    "    doc_split[val] = len(doc[val].split(sep='.')) - 1\n",
    "\n",
    "# ----------------------------------------------- PREPARAMOS EL BLOQUE DE TEXTO PARA GPT-3\n",
    "doc = \" \".join(doc)\n",
    "\n",
    "print(doc)\n",
    "print(doc_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos el bloque de texto preparado, hacemos una única llamada a GPT-3 para pedirle que traduzca, a un idioma determinado, el texto que tenemos.\n",
    "\n",
    "Algo que debemos tener en cuenta es que GPT-3, a la hora de generar la respuesta, tal como construimos la petición, lo primero que generará es el espacio en blanco que hay detrás de los dos puntos de la solicitud; podemos evitar que aparezca este guardando directamente en la variable donde almacenamos la respuesta cogiendo desde el primer caracter y no toda la respuesta.\n",
    "\n",
    "**¿Por qué aparece este espacio?** A la hora de interpretar un resultado, OpenAi recomienda que no existan espacios en blanco después del texto de solicitud ni tampoco saltos de línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In a village of La Mancha, name I don\\'t want to remember, lately a gentleman of the kind of lance in the sheath, old shield, the lean horse and the hound runner lived. The cattle on the most nights, the mourning and the take away on the Saturdays, the boiled lentils on Fridays, some diners on the Sundays, and the rest of the stuff with the gabardine ones, the fine pants for the holidays and the Saturdays with the fine gabardine, and the days of the week with the slippers of the same stuff. In his house lived an old woman over the forty and the niece of the twenty ones. And a farmhand and a worker who saddled the runner as well as he took the scythe. The age of the gentleman had about fifty years. He was of robust complexion, thick skin, lean face, and he was the man of the early riser and the hunt. They say that he had the nickname of \"Quijada\" or \"Quesada\", but in this there is some difference of the authors who wrote on this subject, although it should be understood that he called himself \"Quijana\", but this is not important for our topic. What is important is that in the narration it does not go beyond the truth.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idioma = 'inglés'\n",
    "\n",
    "# ----------------------------------------------- TRADUCCIÓN CON GPT-3\n",
    "entrada = 'Original: ' + doc + '\\nTraducido al'+ idioma + ':'\n",
    "traduccion = openai.Completion.create(engine='davinci',\n",
    "                                      prompt=entrada,\n",
    "                                      temperature=0.81,\n",
    "                                      stop=['\\n', 'Traducido al'+ idioma + ':'],\n",
    "                                      max_tokens = int(len(doc)))\n",
    "doc_traducido = traduccion['choices'][0]['text'][1:]\n",
    "doc_traducido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta respuesta de GPT-3 que tenemos almacenada en **doc_traducido** debemos reconstruirla para que vuelva a añadir los párrafos tal como debería aparecer; para lo que aplicaremos el diccionario que generamos al inicio **doc_split**.\n",
    "\n",
    "Una vez hemos hecho eso, lo único que nos falta es guardar el archivo y revisar que lo haya hecho correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"In a village of La Mancha, name I don't want to remember, lately a gentleman of the kind of lance in the sheath, old shield, the lean horse and the hound runner lived. The cattle on the most nights, the mourning and the take away on the Saturdays, the boiled lentils on Fridays, some diners on the Sundays, and the rest of the stuff with the gabardine ones, the fine pants for the holidays and the Saturdays with the fine gabardine, and the days of the week with the slippers of the same stuff. In his house lived an old woman over the forty and the niece of the twenty ones.\", 'And a farmhand and a worker who saddled the runner as well as he took the scythe. The age of the gentleman had about fifty years. He was of robust complexion, thick skin, lean face, and he was the man of the early riser and the hunt. They say that he had the nickname of \"Quijada\" or \"Quesada\", but in this there is some difference of the authors who wrote on this subject, although it should be understood that he called himself \"Quijana\", but this is not important for our topic.', 'What is important is that in the narration it does not go beyond the truth.']\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------- REGENERAR LOS PÁRRAFOS\n",
    "# ------------------------ Separamos todas las frases y le volvemos a añadir el punto a cada frase\n",
    "doc_trad_split = doc_traducido.split(sep='.')\n",
    "#puntos = [str(frase) + '.' for frase in doc_trad_split]\n",
    "#puntos.remove('.')\n",
    "\n",
    "# ------------------------ Utilizamos doc_split para volver a generar los párrafos correctamente\n",
    "parrafos = []\n",
    "for n in range(len(doc_split)):\n",
    "    parrafos.append(doc_trad_split[:doc_split[n]])\n",
    "    doc_trad_split = doc_trad_split[doc_split[n]:]\n",
    "\n",
    "# ------------------------ Unimos cada párrafo que está sepada por frases en listas dentro de la lista del documento\n",
    "doc_final = ['.'.join(parrafo) for parrafo in parrafos]\n",
    "doc_final = [str(parrafo.lstrip()) + '.' for parrafo in doc_final]\n",
    "print(doc_final)\n",
    "\n",
    "# ----------------------------------------------- GUARDADO DEL DOCUMENTO\n",
    "doc_TRAD = Document()\n",
    "for parrafo in doc_final:\n",
    "    doc_TRAD.add_paragraph(parrafo)\n",
    "\n",
    "doc_TRAD.save('./documentos/traduccion_'+idioma+'.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Para poder usar correctamente GPT-3 es necesario entender su funcionamiento y, sobre todo, tener en cuenta que a veces, si el motoro o la temperatura no es la adecuada, no respondera como esperamos. Es necesario, por tanto, que revisemos los resultados que da. Sin duda, los bloques de texto a GPT-3 le sientan mejor que ir frase por frase; eso no significa que, al encontrarse caracteres especiales, pueda decidir *irse por las ramas*.\n",
    "\n",
    "Hay que tener en cuenta, además, que OpenAi limita el número de palabras máximo que el modelo genera de una vez, habría que valorar según el caso si utilizar el código para hacer estas traducciones tal como aparece en el cuaderno 2.1 (y hacer la traducción por párrafos), o generar un nuevo planteamiento del problema en donde este trabajo sea reiterativo sobre el texto, donde las respuestas generadas vayan incluyéndose en la siguiente iteración para que GPT-3 interprete todo el conjunto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-code\"></i> **Este cuaderno ha sido creado con la ayuda de GPT-3.**\n",
    "<hr/>\n",
    "    \n",
    "**Si tienes alguna duda relacionada con estos cuadernos, puedes contactar conmigo:**\n",
    "Mª Reyes R.P. (Erebyel). **[Web](https://www.erebyel.es/) • [Twitter](https://twitter.com/erebyel) • [Linkedin](https://www.linkedin.com/in/erebyel/)**.\n",
    "    \n",
    "<hr/>\n",
    "    \n",
    "<i class=\"fa fa-plus-circle\"></i> **Fuentes:**\n",
    "* ***Documentación de la Beta de OpenAI***: https://beta.openai.com/docs/introduction\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
